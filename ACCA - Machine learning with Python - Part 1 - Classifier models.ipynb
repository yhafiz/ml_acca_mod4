{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://courses.edx.org/asset-v1:ACCA+ML001+2T2021+type@asset+block@acca-logo.jpg\" alt=\"ACCA logo\" style=\"width: 400px;\"/>\n",
    "\n",
    "# Machine learning with Python\n",
    "## Part 1 - Classifier models\n",
    "\n",
    "* **Course:** __Machine learning with Python for finance professionals__ by ACCA\n",
    "* **Instructor:** [Coefficient](https://coefficient.ai) / [@CoefficientData](https://twitter.com/CoefficientData)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "RFM modelling dataset\n",
    "</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3k rows, 15 columns\n",
    "df = pd.read_csv(\"RFM data - train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data in critical columns\n",
    "df = df.dropna(subset=['Frequency', 'Recency', 'Monetary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the segments?\n",
    "Review the chart below. It shows four pre-defined customer segments:\n",
    "- **VIPs** are high value and/or active customers.\n",
    "- **New** customers are lower value but active recently.\n",
    "- **Passive** customers are more occasional, possibly high value but not active recently.\n",
    "- **At risk** customers are low value and not seen for a while (possibly lost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=100, alpha=0.6, data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Simple Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidenote: `.apply()` with rows\n",
    "Our classifier will read in each row, one by one, and make decisions based on various columns within that row. Is `Recency` large? Is `Monetary` small?\n",
    "\n",
    "We can use the pandas `.apply()` function to achieve this, by applying it to whole rows at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously we've seen .apply() used on a single column\n",
    "df.Monetary.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Monetary.apply(round).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can use .apply() on the whole dataframe. What does the `.apply()` function get, the row or the column?\n",
    "\n",
    "It depends! Pass `axis=0` for columns and `axis=1` for rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column totals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Frequency', 'Monetary']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .apply(sum, axis=0) applies the sum() function to each column, i.e. column totals\n",
    "df[['Frequency', 'Monetary']].apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row totals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .apply(sum, axis=1) applies the sum() function to each row, i.e. row totals\n",
    "df[['Frequency', 'Monetary']].apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple classifier that predicts that all customers seen more than 800 days ago are `At risk`. All other customers are classed as `VIP`.\n",
    "\n",
    "This classifier will get:\n",
    "1. **Some** of the `At risk` group correct ‚û° _it gets 48% of these correct_\n",
    "2. **All** of the `VIP` correct ‚û° _it gets 100% of these correct_\n",
    "3. **All other samples** incorrect! ‚û° _it will score 0% on the other groups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=100, alpha=0.6, data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[0]\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(row):\n",
    "    if row['Recency'] > 800:\n",
    "        return 'At risk'\n",
    "    else:\n",
    "        return 'VIP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(my_classifier, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier(row):\n",
    "    if row['Recency'] > 800:\n",
    "        return 'At risk'\n",
    "    else:\n",
    "        return 'VIP'\n",
    "\n",
    "df['Predictions'] = df.apply(my_classifier, axis=1)\n",
    "df['Correct'] = (df.Predictions == df.Segment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see here which points were predicted correctly (green) vs incorrectly (red).\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Correct', palette=['red', 'green'], data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = \"what percent were correctly predicted?\"\n",
    "df.Correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using f-strings + formatting as a percentage to 1dp\n",
    "print(f\"Accuracy = {df.Correct.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we break this accuracy out by segment?\n",
    "df.groupby('Segment').Correct.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### üö© Exercise...build a better classifier\n",
    "> 1. Look at the RFM scatterplot above and try to build a function that classifies the data more accurately. Use if-else statements and pandas functions only.\n",
    "> 2. Measure the accuracy of your classifier using the accuracy calculation above (\"total correct over total samples\").\n",
    "> 3. Your classifier should be able to achieve well above 60% accuracy on this problem, above 70% is good, above 80% is very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=100, alpha=0.6, data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "#    YOU SHOULD EXTEND THE FUNCTION BELOW BY ADDING SOME MORE IF/ELIF CLAUSES\n",
    "\n",
    "\n",
    "def my_classifier(row):\n",
    "    if row['Recency'] > 800:\n",
    "        return 'At risk'\n",
    "    else:\n",
    "        return 'VIP'\n",
    "\n",
    "df['Predictions'] = df.apply(my_classifier, axis=1)\n",
    "df['Correct'] = (df.Predictions == df.Segment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see here which points were predicted correctly (green) vs incorrectly (red).\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Correct', palette=['red', 'green'], data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = \"what percent were correctly predicted?\"\n",
    "print(f\"Accuracy = {df.Correct.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><i class=\"fa fa-check-square\" aria-hidden=\"true\"></i>&nbsp; Reflect</b><br>\n",
    "\n",
    "Consider the following questions before moving on:\n",
    "\n",
    "1. How simple could this if-else classifier be while remaining relatively accurate?\n",
    "<br/><br/>\n",
    "\n",
    "2. How complicated could this if-else classifier be? Could you get to 100% accuracy, given enough if-else statements, and nested if-else statements? (The demo classifier used two if-else statements. What if we had 200? 2000?)\n",
    "<br/><br/>\n",
    "\n",
    "3. Which if-else classifier do you think might work better against new data that it hasn't yet seen? A simple classifier, your classifier, or a highly complex classifier that achieves high accuracy on an initial dataset? Why?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Testing classifiers on unseen data\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "Let's test your classifier against data it hasn't yet seen. This dataset contains more samples from the same overall RFM dataset so it shares the same patterns and characteristics, just not the exact same data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, drop rows with missing values in either the Recency, Frequency or Monetary columns.\n",
    "df_test = (\n",
    "    pd.read_csv(\"RFM data - test.csv\")\n",
    "    .dropna(subset=['Frequency', 'Recency', 'Monetary'])\n",
    ")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=30, alpha=0.4, data=df_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "df_test['Predictions'] = df_test.apply(my_classifier, axis=1)\n",
    "\n",
    "# Calculate \"test set accuracy\"\n",
    "df_test['Correct'] = (df_test.Predictions == df_test.Segment)\n",
    "\n",
    "print(f\"Test set accuracy = {df_test.Correct.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the areas that were predicted correctly.\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Correct', palette=['red', 'green'], alpha=0.3, data=df_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Decision trees in scikit-learn\n",
    "</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://courses.edx.org/asset-v1:ACCA+ML001+2T2021+type@asset+block@ml_map.png\" alt=\"ML map\" style=\"width: 800px;\"/>\n",
    "\n",
    "[scikit-learn](https://scikit-learn.org/stable/) is an open source library for machine learning in Python. It's built on top of NumPy and matplotlib so it works great with pandas DataFrames. It features a curated yet wide array of techniques for [supervised learning](https://scikit-learn.org/stable/supervised_learning.html) (classification and regression), [unsupervised learning](https://scikit-learn.org/stable/unsupervised_learning.html) (clustering, dimensional reduction), [model tuning, validation & selection](https://scikit-learn.org/stable/model_selection.html#model-selection) as well as handy utilities for [preprocessing datasets](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "\n",
    "scikit-learn is a production-grade tool for machine learning and is [one of the most popular machine learning libraries on GitHub](https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/) behind [TensorFlow](https://www.tensorflow.org/) which is primarily designed for working with [deep learning models](https://en.wikipedia.org/wiki/Deep_learning). For tabular datasets (i.e. not images or sound) that are relatively \"small\" (as a rough benchmark, define \"small\" as half your computer's RAM memory, so anything up to 4GB is considered small), scikit-learn is the ideal tool for the job.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start working with Decision Trees in scikit-learn. To learn more, check out the excellent [user guide for decision trees](https://scikit-learn.org/stable/modules/tree.html) on the scikit-learn documentation site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn is easy to typo...so they import from \"sklearn\" instead\n",
    "\n",
    "# We will need a few modules for the next sections. A module is just a file that contains functions.\n",
    "from sklearn import model_selection, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input (pandas DataFrame) & target output (pandas Series)\n",
    "X = df[['Recency', 'Monetary']]\n",
    "y = df.Segment\n",
    "\n",
    "# Repeat for the test set\n",
    "X_test = df_test[['Recency', 'Monetary']]\n",
    "y_test = df_test.Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = tree.DecisionTreeClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "df['Predictions'] = model.predict(X)\n",
    "df['Correct'] = (df.Predictions == y)\n",
    "print(f\"Training set accuracy = {df.Correct.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by calculating the test set accuracy\n",
    "\n",
    "# First, make some predictions for the test set\n",
    "df_test['Predictions'] = model.predict(X_test)\n",
    "\n",
    "# Second, note down which we got correct\n",
    "df_test['Correct'] = (df_test.Predictions == y_test)\n",
    "\n",
    "# Finally, calculate the accuracy\n",
    "print(f\"Test set accuracy = {df_test.Correct.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which areas were predicted correctly by the decision tree.\n",
    "sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Correct', palette=['red', 'green'], alpha=0.3, data=df_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarise the situation:\n",
    "\n",
    "| Model | Complexity | Training Dataset Accuracy | Test Dataset Accuracy |\n",
    "| -- | -- | -- | -- |\n",
    "| Rule-based classifier (demo) | Low | 40.8% | 40.2% |\n",
    "| Rule-based classifier (our solution code) | Medium | 84% | 75% |\n",
    "| Decision Tree classifier | High | 100% | 70.2% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Visualising decision trees\n",
    "</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you right-click on the generated figure below, you can then either download it or open it in a new browser tab. Either of these options should allow you to then zoom in on the detail of the decision tree's individual nodes and split criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 18))\n",
    "\n",
    "tree.plot_tree(\n",
    "    model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['At risk', 'New', 'Passive', 'VIP'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    precision=1,\n",
    "    fontsize=8,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on the very top of this tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 8))\n",
    "\n",
    "tree.plot_tree(\n",
    "    model,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['At risk', 'New', 'Passive', 'VIP'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=12,\n",
    "    precision=1,\n",
    "    max_depth=2,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the original training data (copied below), does this make sense?\n",
    "\n",
    "1. The first split asks: **Is `Recency` < 290?**\n",
    "2. If `Recency < 290`, go left and ask: **Is `Monetary` < 1196?**\n",
    "  - If `Monetary < 1196`, predict we're likely `New`.\n",
    "  - If `Montary > 1196`, predict we're likely `VIP`.\n",
    "3. If `Recency > 290`, go right and ask: **Is `Recency` < 650?**\n",
    "  - If `Recency < 650`, predict we're likely `Passive`.\n",
    "  - If `Recency > 650`, predict we're likely `At risk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "graph = sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=100, alpha=0.6, data=df);\n",
    "\n",
    "# Let's add the splits visually below\n",
    "graph.axvline(290, color='black', linestyle='--')   # Recency < 290?\n",
    "graph.axvline(650, color='black', linestyle='--')   # Recency < 650?\n",
    "graph.axhline(y=1196, xmin=0, xmax=.24, color='black', linestyle='--')  # Monetary < 1196?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><i class=\"fa fa-check-square\" aria-hidden=\"true\"></i>&nbsp; Check</b><br>\n",
    "\n",
    "Go back and check your if-else based solution to this problem. How does it compare to the splits derived automatically by the DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Cross-validation\n",
    "</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine our training & test data into a single dataset.\n",
    "\n",
    "# We add the if-condition to prevent duplication of data in\n",
    "# case you run the cell multiple times.\n",
    "if len(df) < 500:\n",
    "    df = pd.concat([df, df_test], axis=0)\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### üö© Exercise\n",
    "> \n",
    "> Let's run through the basic pattern of using sklearn, this time with the full 2442 rows in the combined `df` dataframe:\n",
    "> 1. Recreate the input dataframe, `X` and the target Series, `y`. This code will be unchanged from before, so just copy it in. We don't need to worry about a test set this time.\n",
    "> 2. Fit a `DecisionTreeClassifier` model to `X` and `y`. This means we're asking the classifier to learn how to predict `y` (the target) given the input `X` (the input).\n",
    "> 3. Instead of generating predictions, counting which were correct, and calculating the accuracy by hand... just call `model.score(X, y)` to do this all in one go. This is the model's \"training set accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create X and y\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fit the model\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate the training set accuracy\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split()`\n",
    "Previously you were given a training set and a test set. How did we make this? Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a small training set (10% of df) and a large test set (90% of df)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train is a pandas DataFrame with 244 rows and 2 columns\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test is a pandas DataFrame with 2198 rows and 2 columns\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train is a pandas Series with 244 rows and no columns (Series don't have columns)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train is a pandas Series with 2198 rows and no columns\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><i class=\"fa fa-check-square\" aria-hidden=\"true\"></i>&nbsp; Check</b><br>\n",
    "\n",
    "Make sure you follow along with the idea of creating a training set and a test set here, and that you understand the required shape for <code>X</code> and <code>y</code>. A <em>very</em> common mistake when using scikit-learn is to try to supply something other than a DataFrame for X, and something other than a Series for y.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate cross-validated accuracy (in just two lines of code!)\n",
    "\n",
    "# First, we fit to the training data\n",
    "model = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Second, we can calculate the accuracy directly using the .score() method\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><i class=\"fa fa-check-square\" aria-hidden=\"true\"></i>&nbsp; Check</b><br>\n",
    "\n",
    "There's a lot going on here. The process is always the same in machine learning:\n",
    "\n",
    "<ol>\n",
    "    <li>Divide your data into train set and test set.</li>\n",
    "    <li>Fit a model to your training data (<code>X_train</code> and <code>y_train</code>).</li>\n",
    "    <li>Make predictions for the unseen dataset <code>X_test</code>.</li>\n",
    "    <li>Compare those predictions with the answers, <code>y_test</code>.</li>\n",
    "    <li>Score it up using a metric such as overall accuracy on the test set.</li>\n",
    "</ol>\n",
    "    \n",
    "If you need another perspective, <a href=\"https://radiopublic.com/data-skeptic-6VVqb6/s1!f1bc6\">this mini-podcast episode is a great accessible primer on cross-validation</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### k-fold cross-validation\n",
    "Like most things in scikit-learn, you don't need to write your own code for this, k-fold cross-validation a built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply a 5-fold cross-validation\n",
    "scores = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the average accuracy across all five folds?\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our \"gold standard\" validation for this problem. If the model is under-fitting or over-fitting, it won't generalise well to the test set and will perform poorly in the k-fold cross-validation process.\n",
    "\n",
    "It's likely that our DecisionTreeClassifier is overfitting due to overcomplexity. Let's try reducing the complexity of this decision tree by setting `max_depth=2` (we will explain what this means shortly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max_depth=2 and re-run the cross-validation scoring.\n",
    "model = tree.DecisionTreeClassifier(max_depth=2).fit(X, y)\n",
    "scores = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tinkering with the `max_depth` argument (a.k.a. \"hyperparameter\") we improved our model. This is a real improvement too, remember, we're using a gold standard validation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### üö© Exercise\n",
    "> **What is the optimal `max_depth` hyperparameter for this problem?**\n",
    "> \n",
    "> 1. First, use a for loop to iterate over a range of values from 1 to 30 (don't forget to exclude 0).\n",
    "> \n",
    "> 2. At each point, save the `max_depth` value as well as the mean cross-validated accuracy for that decision tree. We've provided an example below on how to save data from for loops into a list of dictionaries. Remember, it's trivial to turn a list of dictionaries into a pandas dataframe.\n",
    "> \n",
    "> 3. Plot `accuracy` (y-axis) vs `max_depth` (x-axis) using Seaborn's **[`lineplot()`](https://seaborn.pydata.org/generated/seaborn.lineplot.html)** function.\n",
    "> \n",
    "> 4. Looking at your plot (or the dataframe of results directly), which value of `max_depth` maximises cross-validated accuracy for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving data from for loops\n",
    "First, a quick reminder on a handy pattern for saving data from loops:\n",
    "1. Initialise an empty list ready to hold some data\n",
    "2. Use a `for` loop to iterate through a list\n",
    "3. Append some data into the empty list\n",
    "4. A list of dictionaries converts quite nicely into a DataFrame\n",
    "5. We can then use Seaborn to visualise the DataFrame.\n",
    "\n",
    "Here we are visualising the formula: $$y = 2^i - i^3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: plotting numbers\n",
    "data_list = []\n",
    "for i in range(12):\n",
    "    data_list.append({\n",
    "        'x': i,\n",
    "        'y': (2**i) - (i**3),\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(data_list)\n",
    "sns.lineplot(x='x', y='y', data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the loop above as a starting point, but instead saving the accuracy for a model with the specified `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a for loop to iterate over a range of values from 1 to 30\n",
    "# (don't forget to exclude 0). At each point, save the max_depth value\n",
    "# as well as the mean cross-validated accuracy for that decision tree.\n",
    "                                                                      \n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy (y-axis) vs max_depth (x-axis) using Seaborn's lineplot() function.\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at your plot (or the dataframe of results directly), which value of\n",
    "# max_depth maximises cross-validated accuracy for this problem?\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### üö© Exercise\n",
    "> Fit a DecisionTreeClassifier with your optimised max_depth to the whole dataset (`X` and `y`).\n",
    "> \n",
    "> Using the code provided earlier, visualise this optimised decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the whole dataset.\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise this \"best case\" model.\n",
    "\n",
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "Random Forests\n",
    "</h2><br>\n",
    "</div>\n",
    "\n",
    "Random Forests are an example of a machine learning [ensemble technique](https://scikit-learn.org/stable/modules/ensemble.html). Many other ensemble methods exist for constructing ensembles of \"base classifiers\" with various voting mechanisms. [Read more about ensemble methods in scikit-learn here](https://scikit-learn.org/stable/modules/ensemble.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a default random forest\n",
    "model = ensemble.RandomForestClassifier().fit(X, y)\n",
    "model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good, 75% cross-validated accuracy is already equivalent to our optimally tuned decision tree! Maybe we can do even better if we tune our random forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ### üö© Exercise\n",
    "> Copy your hyperparameter tuning code from earlier, and identify the best `n_estimators` for a `RandomForestClassifier` for this problem. You should assume `max_depth=5`, i.e. assuming your for loop references `n_estimators` in some range:\n",
    "> \n",
    "> ```python\n",
    "> model = ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=5).fit(X, y)\n",
    "> ```\n",
    "> \n",
    "> Tip: don't use `range()` here, it will be needlessly slow. Instead try iterating over just the following values in your for loop: `[1, 5, 10, 20, 30, 40, 50, 60, 75, 100, 150]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è ENTER YOUR SOLUTION HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You should get a five-fold cross-validated accuracy in the region of 70%-80% - not bad for a tricky problem! There's a lot more parameters we could play around with and optimise (you can see all the [hyperparameters of scikit-learn's `RandomForestClassifier()` here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), but we'll leave this for now. Which feature is more important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators=45, max_depth=5).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting importance of features\n",
    "features = X.columns\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "features_df = (\n",
    "    pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "    .sort_values(by='Importance Score', ascending=False)\n",
    ")\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=features_df, x='Features', y='Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that `Recency` is the major driver of segment classification, far more than `Monetary`. This makes sense, given the scatterplots we saw earlier which differentiated mostly along the `Recency` axis with `Monetary` only really making a difference to differentiate between `VIP` and `New`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #BA001E; border: 0px; -moz-border-radius: 10px; -webkit-border-radius: 10px;\">\n",
    "<h2 style=\"color: white\">\n",
    "The RFM Model\n",
    "</h2><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "graph = sns.scatterplot(x=\"Recency\", y=\"Monetary\", hue='Segment', s=100, alpha=0.6, data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been trying to reverse engineer an [RFM segmentation](https://clevertap.com/blog/rfm-analysis/) which was determined using a rule-based system. Here is the original RFM analysis for this company.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://courses.edx.org/asset-v1:ACCA+ML001+2T2021+type@asset+block@rfm.png\" alt=\"RFM heatmap\" style=\"width: 400px;\"/>\n",
    "        </td>\n",
    "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
    "        <td>\n",
    "            <img src=\"https://courses.edx.org/asset-v1:ACCA+ML001+2T2021+type@asset+block@rfm.jpg\" alt=\"RFM matrix\" style=\"width: 400px;\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | Description | Low | High |\n",
    "| -- | -- | -- | -- |\n",
    "| `Fscore` | Frequency score | Low frequency, e.g. customers visit once/year | High frequency, e.g. daily visits |\n",
    "| `Rscore` | Recency score | Low recency, e.g. customers not seen for a while | High recency, e.g. seen today |\n",
    "| `Mscore` | Monetary score (cell colour) | Red = low percentage of total revenue | Green = high percentage of total revenue |\n",
    "\n",
    "This RFM model suggests that:\n",
    "1. **High frequency customers are generating the most revenue**.\n",
    "  - These are top-row customers in the above plot.\n",
    "  - Treat like `VIPs` and target for further monetisation, regardless of recency.\n",
    "  - There are no high-frequency low-recency customers, hence no revenue; this makes sense intuitively.\n",
    "2. **Medium frequency low recency customers shouldn't be ignored.**\n",
    "  - These are middle-left in the plot above.\n",
    "  - These are loyal `Passive` customers and require a different CRM strategy to VIPs.\n",
    "3. **Medium-to-high recency + low-to-medium frequency => new customers.**\n",
    "  - This is a large block in the bottom-right four squares of the plot above.\n",
    "  - Target habit formation and shifting customers up & towards the right towards the `VIPs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "graph = sns.scatterplot(x=\"Recency\", y=\"Frequency\", hue='Segment', s=100, alpha=0.6, data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Please proceed to the next part of the course when you are ready.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (acca-ml4fp)",
   "language": "python",
   "name": "acca-ml4fp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
